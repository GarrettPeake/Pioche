const fs = require("fs");
const path = require("path");
const crypto = require("crypto");
const toml = require("@iarna/toml/");
const cwd = require("process").cwd();
const glob = require("glob");


/**
 * Pioche build script
 * Intakes pioche.config.js
 * Creates entry.ts
 * Creates wrangler.toml
 * Processes migrations
 */

// TODO: Generate wrangler.toml
// import + export from entry.ts
// import everything, list everything to prevent shaking, then reexport durable objects.
module.exports = async function(logger){
    logger.fglog("== Building pioche app ==", "green");

    // Ensure we're in the base directory by checking for package.json
    try{
        // eslint-disable-next-line @typescript-eslint/no-unused-vars
        const _ = require(path.join(path.relative(__dirname, cwd), "package.json"));
    } catch {
        logger.fgerror("Run build command in project directory");
        return;
    }

    // Retrieve config
    const config = await getConfig(logger) || createDefaultConfig(logger) || await getConfig(logger); // Genius!
    console.log(config);

    // Retrieve dotenv
    const dotenv = getDotenv(logger) || createDefaultDotenv(logger) || getDotenv(logger);
    console.log(dotenv);

    // Discover all controllers
    const controllers = await discoverControllers(logger);
    if(controllers.workers.length + controllers.durable_objects.length === 0){
        logger.fgerror("No controllers implemented, stopping build");
        return;
    }

    // Retrieve wrangler.toml
    const wranglerToml = getWranglerToml(logger);
    if(!wranglerToml) return;


    /**
     * Update our wrangler.toml file
     */
    logger.begin("Updating wrangler.toml");
    updateWranglerToml(wranglerToml, config, dotenv);
    logger.finish();

    // Generate our entry file
    logger.begin("Generating entry file");
    generateEntry(config);
    logger.finish();
};

async function getConfig(logger){
    logger.begin("Opening pioche.config.js from cwd");
    try{
        const config = await import(
            path.join(path.relative(__dirname, cwd), "pioche.config.js")
        ).then((m) => m.default);
        logger.finish();
        return config;
    } catch (e) {
        logger.fail("Unable to locate pioche.config.js");
    }
}

function createDefaultConfig(logger) {
    logger.begin("...");
    const contents =
        "// ===============================================\n" +
        "// Autogenerated config file\n" +
        "// Use this to configure your workers environment\n"+
        "// ===============================================\n\n" +
        "export default {\n" +
        "    prehandlers: [],\n" +
        "    posthandlers: [],\n" +
        "    kvBindings: [],\n" +
        "    serviceBindings: [],\n" +
        "}\n";
    // Write the file
    fs.writeFileSync(path.join(cwd, "/pioche.config.js"), contents);
    logger.info("Generated new pioche.config.js");
}

function getDotenv(logger){
    logger.begin("Opening and parsing .env");
    const dotenv = require("dotenv").config().parsed;
    if(!dotenv)
        logger.fail("No .env file in directory");
    else{
        logger.finish();
        return dotenv;
    }
}

function createDefaultDotenv(logger) {
    logger.begin("...");
    const key = crypto.randomBytes(32).toString("hex");
    const contents =
        "# =============================================\n" +
        "# Define environment variables here\n" +
        "# Never commit your .env file\n"+
        "# =============================================\n\n"+
        `JWT_SECRET=${key}`;
    // Write the file
    fs.writeFileSync(path.join(cwd, "/.env"), contents);
    logger.info("Generated new .env with secure JWT secret");
}

function getWranglerToml(logger){
    logger.begin("Opening and parsing wrangler.toml");
    try{
        const tomlRaw = fs.readFileSync(path.join(cwd, "wrangler.toml"), "utf8");
        if(tomlRaw){
            try{
                const wranglerToml = toml.parse(tomlRaw);
                logger.finish();
                return wranglerToml;
            } catch (e) {
                logger.error("Error parsing wrangler.toml on line " + e.line + ", column " +
                e.column + ": " + e.message);
                return;
            }
        }
    } catch {
        logger.info("No wrangler.toml found, generating");
        return {};
    }
}

async function discoverControllers(logger){
    logger.begin("Discovering controllers");
    const js = glob.sync(cwd + "/src/**/*.js", {});
    const cjs = glob.sync(cwd + "/src/**/*.cjs", {});
    const mjs = glob.sync(cwd + "/src/**/*.mjs", {});
    const jsx = glob.sync(cwd + "/src/**/*.jsx", {});
    const ts = glob.sync(cwd + "/src/**/*.ts", {});
    const tsx = glob.sync(cwd + "/src/**/*.tsx", {});
    const files = [].concat(js, cjs, mjs, jsx, ts, tsx);
    if(!files.length){
        logger.info("No js, jsx, cjs, mjs, ts, or tsx files found, only files under src/ can be discovered");
        return;
    }
    logger.finish();
    const controllers = {workers: new Set(), durable_objects: new Set()};
    for(const filename of files){
        if(path.basename(filename) !== "entry.ts") { // Our own entry.ts will give "false" exports
            logger.fgwrite("    > FILE: " + path.basename(filename), "yellow");
            const exports = await getExports(filename, logger);
            for(const [name, value] of Object.entries(exports)){
                let proto = value;
                while(proto.name !== undefined){
                    if(proto.name === "DurableObjectController"){
                        controllers.durable_objects.add(name);
                        break;
                    }
                    if(proto.name === "WorkerController"){
                        controllers.workers.add(name);
                        break;
                    }
                    proto = proto.__proto__;
                }
            }
        }
    }
    controllers.workers = Array.from(controllers.workers);
    controllers.durable_objects = Array.from(controllers.durable_objects);
    return controllers;
}

/**
 * Creates an updated wrangler.toml with migrations, bindings, and build command set
 * @param contents Contents of the original wrangler.toml
 * @param config pioche.config.js config file
 */
function updateWranglerToml(logger, contents, config, dotenv){
    const header =
        "# ============================================================================\n" +
        "# Required for workers runtime, never commit this file\n" +
        "# Pioche build process overwrites all bindings, migrations, and build commands\n" +
        "# ============================================================================\n\n";
    // Ensure TOML has fields for required elements

    // WIPE: Durable Object Bindings
    contents.durable_objects = { bindings: [] };

    // FWD: Migrations
    if(!contents.migrations){ contents.migrations = []; }

    // WIPE: KV Bindings
    contents.kv_namespaces = [];
    // Write out the new file
    const tomlOutputString = header + toml.stringify(contents);
    fs.writeFileSync(path.join(cwd, "wrangler.toml"), tomlOutputString);
}

function generateEntry(logger, config){
    const header =
        "// ===================================================\n" +
        "// Created automatically, edits won't have any effect\n" +
        "// ===================================================\n\n" +
        "import { DefaultHandlers } from \"pioche\";\n";

    const footer = "export default DefaultHandlers;\n";
    // TODO: WE could just copy the import statements from the config file
    const entryContents = "";
    config.controllers?.forEach((controller) => {
        console.log(controller);
    });
    // Write the file
    fs.writeFileSync(path.join(cwd, "src/entry.ts"),  header + entryContents + footer);
}

async function getExports(filename, logger){
    // Disable console logs for cleaner output
    const clog = console.log;
    console.log = () => {};
    let exports;
    // If ts we'll need to transpile it before checking for exports
    if([".ts", ".cts", ".mts", ".tsx"].includes(path.extname(filename))){
        logger.fgwrite(" > transpiling", "yellow");
        require("esbuild").buildSync({
            entryPoints: [filename],
            outfile: path.join(cwd, "piochetemp/temp.mjs"),
            logLevel: "silent"
        });
    }
    logger.fgwrite(" > importing", "yellow");
    try{
        exports = await import(path.join(cwd, "piochetemp/temp.mjs"));
        logger.fglog(" > success", "yellow");
    } catch (e) {
        logger.fglog(" > failed", "red");
        console.log(e);
    }
    // Delete our temp directory if it exists
    if(fs.existsSync("piochetemp")) fs.rmSync("piochetemp", {recursive: true});
    // Re-enable console.log()
    console.log = clog;
    return exports;
}