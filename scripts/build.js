const fs = require("fs");
const path = require("path");
const crypto = require("crypto");
const toml = require("@iarna/toml/");
const cwd = require("process").cwd();
const glob = require("glob");
const esbuild = require("esbuild");

function makeTempDir(){
    if(!fs.existsSync(path.join(cwd, "piochetemp")))
        fs.mkdirSync(path.join(cwd, "piochetemp"), ()=>{});
}

function rmTempDir(){
    if(fs.existsSync("piochetemp"))
        fs.rmSync("piochetemp", {recursive: true});
}

module.exports = async function(logger){
    logger.fglog("== Building pioche app ==", "green");

    // Create a temporary build directory
    makeTempDir();

    // Ensure we're in the base directory by checking for package.json
    try{
        require(path.join(path.relative(__dirname, cwd), "package.json"));
    } catch {
        logger.fgerror("Run build command in project directory");
        return;
    }

    // Retrieve config
    const config = await getConfig(logger) || createDefaultConfig(logger);
    if(config === -1) return;

    // Retrieve config imports
    const tbimports = await getConfigImports(logger);

    // Retrieve dotenv
    const dotenv = getDotenv(logger) || createDefaultDotenv(logger);

    // Discover all controllers
    const controllers = await discoverControllers(logger);
    if(Object.entries({...controllers.workers, ... controllers.durable_objects}).length === 0
        && config.extControllers?.length === 0){
        logger.fgerror("No controllers specified, stopping build");
        return;
    }

    // Find external controllers
    const extControllers = await checkExternalControllers(logger, config.extControllers);

    // Retrieve wrangler.toml
    const wranglerToml = getWranglerToml(logger);
    if(wranglerToml === -1) return;

    // Update our wrangler.toml file
    updateWranglerToml(logger, wranglerToml, config, dotenv, controllers, extControllers);

    // Generate our entry file
    generateEntry(logger, config, controllers, extControllers, tbimports);

    // Delete our temp directory if it exists
    rmTempDir();
};

async function getConfig(logger){
    logger.begin("Opening pioche.config.js from cwd");
    try{
        const config = await import(
            path.join(path.relative(__dirname, cwd), "pioche.config.js")
        ).then((m) => m.default);
        // TODO: Add all potential controllers here
        logger.finish();
        return config;
    } catch (e) {
        if(fs.existsSync(path.join(cwd, "pioche.config.js"))){
            logger.fail("Unable to parse pioche.config.js");
            console.log(e);
            return -1;
        }
        else
            logger.info("Unable to locate pioche.config.js");
    }
}

function createDefaultConfig(logger) {
    logger.begin("Generating new pioche.config.js");
    const defConfig = {
        extControllers: [],
        prehandlers: [],
        posthandlers: [],
        kv_namespaces: {},
    };
    const contents =
        "// =================================================\n" +
        "// Autogenerated config file\n" +
        "// Use this to configure your workers environment\n"+
        "// Controllers in ../src are automatically included\n" +
        "// =================================================\n\n" +
        "export default " +
        JSON.stringify(defConfig, undefined, 4).replaceAll("\"", "");
    // Write the file
    fs.writeFileSync(path.join(cwd, "/pioche.config.js"), contents);
    logger.finish();
    return defConfig;
}

/**
 * Return a list of  
 */
async function checkExternalControllers(logger, extControllers){
    logger.begin("Discovering imported DO controllers");
    const controllers = {workers: [], durable_objects: []};
    for(const value of extControllers){
        checkPotentialController(value, (name) => {
            controllers.durable_objects.push(name);
        }, (name) => {
            controllers.workers.push(name);
        });
    }
    logger.finish();
    return controllers;
}

async function getConfigImports(logger){
    logger.begin("Copying imports from pioche.config.js");
    // Use es-build to flatten everything
    await esbuild.build({
        entryPoints: ["pioche.config.js"],
        outfile: "piochetemp/config.js",
    });
    // Find the export default statement
    const contents = fs.readFileSync(path.join(cwd, "piochetemp/config.js"), "utf8");
    const start = contents.indexOf("export default");
    let end = start;
    let brackets = 0;
    [...contents.slice(start)].forEach((c, i) => {
        brackets += c === "{" ? 1 : (c === "}" ? -1 : 0);
        if(brackets === 0){
            end = start + i;
        }
    });
    logger.finish();
    return (contents.slice(0,start) + contents.slice(end)).trim();
}

function getDotenv(logger){
    logger.begin("Opening and parsing .env");
    const dotenv = require("dotenv").config().parsed;
    if(!dotenv)
        logger.info("No .env file in directory");
    else{
        logger.finish();
        return dotenv;
    }
}

function createDefaultDotenv(logger) {
    logger.begin("Generating new .env with secure JWT secret");
    const key = crypto.randomBytes(32).toString("hex");
    const contents =
        "# =============================================\n" +
        "# Define environment variables here\n" +
        "# Never commit your .env file\n"+
        "# =============================================\n\n"+
        `JWT_SECRET=${key}`;
    // Write the file
    fs.writeFileSync(path.join(cwd, "/.env"), contents);
    logger.finish();
    return {JWT_SECRET: key};
}

async function discoverControllers(logger){
    logger.begin("Discovering controllers");
    const files = [].concat(
        glob.sync(cwd + "/src/**/*.js", {}),
        glob.sync(cwd + "/src/**/*.cjs", {}),
        glob.sync(cwd + "/src/**/*.mjs", {}),
        glob.sync(cwd + "/src/**/*.jsx", {}),
        glob.sync(cwd + "/src/**/*.ts", {}),
        glob.sync(cwd + "/src/**/*.mts", {}),
        glob.sync(cwd + "/src/**/*.cts", {}),
        glob.sync(cwd + "/src/**/*.tsx", {})
    ).filter((name) => path.basename(name) !== "entry.ts");
    if(!files.length){
        logger.info("No JS or TS files found in ./src (Checked .js/jsx .m/cjs .ts/tsx .m/cts)");
        return;
    }
    logger.finish();
    const controllers = {workers: {}, durable_objects: {}};
    for(const filename of files){
        logger.fgwrite("    > FILE: " + path.basename(filename), "yellow");
        const exports = await getExports(filename, logger);
        for(const [, value] of Object.entries(exports)){
            const importpath = path.relative(path.join(cwd, "src"), filename);
            checkPotentialController(value, (name) => {
                controllers.durable_objects[name] = importpath;
            }, (name) => {
                controllers.workers[name] = importpath;
            });
        }
    }
    return controllers;
}

function checkPotentialController(value, doCallback, workerCallback){
    let proto = value;
    const name = proto.name;
    while(proto.name !== undefined){
        if(proto.name === "DurableObjectController"){
            // Don't care where it comes from as long as it's exported
            doCallback?.(name);
            break;
        }
        if(proto.name === "WorkerController"){
            // Don't care where it comes from as long as it's exported
            workerCallback?.(name);
            break;
        }
        proto = proto.__proto__;
    }
}

function getWranglerToml(logger){
    logger.begin("Opening and parsing wrangler.toml");
    try{
        const tomlRaw = fs.readFileSync(path.join(cwd, "wrangler.toml"), "utf8");
        if(tomlRaw){
            try{
                const wranglerToml = toml.parse(tomlRaw);
                logger.finish();
                return wranglerToml;
            } catch (e) {
                logger.error("Error parsing wrangler.toml on line " + e.line + ", column " +
                e.column + ": " + e.message);
                return -1;
            }
        }
    } catch {
        logger.info("No wrangler.toml found, generating");
        return {};
    }
}

/**
 * Creates an updated wrangler.toml with migrations, bindings, and build command set
 * @param contents Contents of the original wrangler.toml
 * @param config pioche.config.js config file
 */
function updateWranglerToml(logger, contents, config, dotenv, controllers, extControllers){
    logger.begin("Generating wrangler.toml");
    const header =
        "# =============================================================================\n" +
        "# Required for workers runtime, never commit this file\n" +
        "# durable_objects, kv_namespaces, migrations, build, and vars autogenerated\n" +
        "# =============================================================================\n\n";
    // Set vars to our .env entries
    contents.vars = dotenv;

    // Set kv_namespaces to our kv_namespaces
    contents.kv_namespaces = [];
    Object.entries(config.kv_namespaces).forEach(([binding, id]) => {
        contents.kv_namespaces.push({binding: binding, id: id});
    });

    // Set Durable Object Bindings
    const oldDOs = contents.durable_objects?.bindings.map((e)=>e.name);
    contents.durable_objects = {
        bindings: [
            ...Object.entries(controllers.durable_objects).map(([e]) => e),
            ...extControllers.durable_objects
        ].map((name) => {
            return {
                name: name,
                class_name: name
            };
        }
    )};
    const newDOs = contents.durable_objects?.bindings.map((e)=>e.name);

    // FWD: Migrations compare oldDOs and newDOs
    if(!contents.migrations) contents.migrations = [];

    // Set the build command
    contents.build = {
        command: "npm run build",
        cwd: "build_cwd",
        watch_dir: "src",
    };

    // Write out the new file
    const tomlOutputString = header + toml.stringify(contents);
    fs.writeFileSync(path.join(cwd, "wrangler.toml"), tomlOutputString);
    logger.finish();
}

function generateEntry(logger, config, controllers, extControllers, tbimports){
    logger.begin("Generating entry file");
    const header =
        "// ===================================================\n" +
        "// Created automatically, edits won't have any effect\n" +
        "// ===================================================\n\n" +
        "import { DefaultHandlers } from \"pioche\";\n" +
        tbimports;

    const footer = "export default DefaultHandlers;\n";
    // TODO: WE could just copy the import statements from the config file
    let entryContents = "";
    // Write the file
    fs.writeFileSync(path.join(cwd, "src/entry.ts"),  header + entryContents + footer);
    logger.finish();
}

async function getExports(filename, logger){
    // Disable console logs for cleaner output
    const clog = console.log;
    console.log = () => {};
    let exports;
    // If ts we'll need to transpile it before checking for exports
    if([".ts", ".cts", ".mts", ".tsx"].includes(path.extname(filename))){
        logger.fgwrite(" > transpiling", "yellow");
        esbuild.buildSync({
            entryPoints: [filename],
            outfile: path.join(cwd, "piochetemp/temp.mjs"),
            logLevel: "silent",
            format: "esm"
        });
    }
    try{
        // Try to import it as a module
        // This will succeed on .mjs, .js/.jsx ES6 modules, and .ts/.tsx/.cts/.mts
        logger.fgwrite(" > importing as ES6", "yellow");
        exports = await import(path.join(cwd, "piochetemp/temp.mjs"));
        logger.fglog(" > success", "green");
    } catch (e) {
        logger.fglog(" > failed", "red");
        try{
            // Try to require it
            // This will succeed on .js/.jsx CJS modules
            logger.fgwrite(" > importing as CJS", "yellow");
            exports = require(path.join(cwd, "piochetemp/temp.mjs"));
            logger.fglog(" > success", "green");
        } catch (e1) {
            console.log(e);
            logger.fglog(" > failed", "red");
        }
    }
    // Re-enable console.log()
    console.log = clog;
    return exports;
}